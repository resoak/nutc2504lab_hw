import os
import pandas as pd
import requests
import torch
from typing import List
from concurrent.futures import ThreadPoolExecutor
from openai import OpenAI
from sentence_transformers import CrossEncoder
from langchain_text_splitters import RecursiveCharacterTextSplitter
from qdrant_client import QdrantClient, models
from rank_bm25 import BM25Okapi
from deepeval.metrics import (
    FaithfulnessMetric, AnswerRelevancyMetric, 
    ContextualRecallMetric, ContextualPrecisionMetric, ContextualRelevancyMetric
)
from deepeval.test_case import LLMTestCase
from deepeval.models import DeepEvalBaseLLM

# === 1. é…ç½®è¨­å®š ===
EMBED_URL = "https://ws-04.wade0426.me/embed"
COLLECTION_NAME = "day6_hw_final_run"
DEVICE = "cpu" 
LOCAL_RERANKER_PATH = os.path.expanduser("~/AI/Models/Qwen3-Reranker-0.6B")
TEMP_CSV = "rag_intermediate_results.csv"  
FINAL_CSV = "day6_HW_final_scores.csv"    

class FastLLM(DeepEvalBaseLLM):
    def __init__(self):
        self.client = OpenAI(api_key="No", base_url="https://ws-05.huannago.com/v1")
    def load_model(self): return self.client
    def generate(self, prompt: str) -> str:
        res = self.client.chat.completions.create(
            model="google/gemma-3-27b-it", 
            messages=[{"role": "user", "content": prompt}], 
            temperature=0
        )
        return res.choices[0].message.content
    async def a_generate(self, prompt: str) -> str: return self.generate(prompt)
    def get_model_name(self): return "Gemma-3"

custom_llm = FastLLM()
q_client = QdrantClient(url="http://localhost:6333")

# === 2. è¼‰å…¥æ¨¡å‹ (å« Padding ä¿®æ­£) ===
print(f"ğŸ› ï¸  æ­£åœ¨è¼‰å…¥ Reranker (Device: {DEVICE})...")
try:
    rerank_model = CrossEncoder(LOCAL_RERANKER_PATH, device=DEVICE, trust_remote_code=True)
    if rerank_model.tokenizer.pad_token is None:
        rerank_model.tokenizer.pad_token = rerank_model.tokenizer.eos_token
        rerank_model.model.config.pad_token_id = rerank_model.tokenizer.eos_token_id
except Exception as e:
    print(f"âš ï¸  æœ¬åœ°æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    rerank_model = CrossEncoder("BAAI/bge-reranker-v2-m3", device=DEVICE)

# === 3. æª¢ç´¢èˆ‡å‹•æ…‹ç¶­åº¦è™•ç† ===
def get_embeddings(texts: List[str]):
    res = requests.post(EMBED_URL, json={"texts": texts, "normalize": True})
    return res.json()["embeddings"]

def advanced_search(query, bm25, all_chunks, top_k=5):
    q_vec = get_embeddings([query])[0]
    search_res = q_client.query_points(collection_name=COLLECTION_NAME, query=q_vec, limit=20).points
    bm25_scores = bm25.get_scores(query.split())
    top_bm25_idx = pd.Series(bm25_scores).nlargest(10).index
    candidates = list(set([h.payload["page_content"] for h in search_res] + [all_chunks[idx] for idx in top_bm25_idx]))
    pairs = [[query, cand] for cand in candidates]
    # batch_size=1 ç¢ºä¿ Qwen3 ç©©å®š
    scores = rerank_model.predict(pairs, batch_size=1, show_progress_bar=False)
    ranked = sorted(zip(candidates, scores), key=lambda x: x[1], reverse=True)
    return [c for c, s in ranked[:top_k]]

# === 4. ä¸»ç¨‹å¼ ===
def main():
    # --- A. æº–å‚™è³‡æ–™èˆ‡å‹•æ…‹ç´¢å¼•å»ºç«‹ ---
    print("ğŸ“– è®€å–æ–‡æœ¬èˆ‡å»ºç«‹ç´¢å¼•ä¸­...")
    with open("qa_data.txt", "r", encoding="utf-8") as f:
        all_chunks = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50).split_text(f.read())
    
    # ã€å‹•æ…‹ç¶­åº¦åµæ¸¬ã€‘
    print("ğŸ” åµæ¸¬ Embedding ç¶­åº¦...")
    sample_embeddings = get_embeddings(["ç¶­åº¦åµæ¸¬æ¸¬è©¦å…§å®¹"])
    vector_dim = len(sample_embeddings[0])
    print(f"âœ… åµæ¸¬åˆ°å‘é‡ç¶­åº¦ç‚º: {vector_dim}")

    if q_client.collection_exists(COLLECTION_NAME): 
        q_client.delete_collection(COLLECTION_NAME)
    
    q_client.create_collection(
        COLLECTION_NAME, 
        vectors_config=models.VectorParams(size=vector_dim, distance=models.Distance.COSINE)
    )

    # æ‰¹æ¬¡å¯«å…¥è³‡æ–™
    print("âš™ï¸  æ­£åœ¨å°‡è³‡æ–™å¯«å…¥å‘é‡åº«...")
    chunk_embeddings = get_embeddings(all_chunks)
    q_client.upsert(
        COLLECTION_NAME, 
        points=[
            models.PointStruct(id=i, vector=v, payload={"page_content": t}) 
            for i, (t, v) in enumerate(zip(all_chunks, chunk_embeddings))
        ]
    )
    bm25 = BM25Okapi([doc.split() for doc in all_chunks])

    df_q = pd.read_csv("questions.csv")
    df_ans = pd.read_csv("questions_answer.csv")
    
    # --- B. ç¬¬ä¸€éšæ®µï¼šç”Ÿæˆ RAG çµæœä¸¦å­˜å…¥ CSV ---
    print(f"\nğŸ”¥ éšæ®µ 1ï¼šé–‹å§‹æª¢ç´¢èˆ‡ç”Ÿæˆå›ç­” (ç¸½è¨ˆ {len(df_q)} é¡Œ)...")
    
    def run_rag(row):
        qid, q_text = row['q_id'], row['questions']
        contexts = advanced_search(q_text, bm25, all_chunks)
        answer = custom_llm.generate(f"è³‡è¨Šï¼š\n{''.join(contexts)}\nå•é¡Œï¼š{q_text}\nå›ç­”ï¼š")
        golden = df_ans[df_ans['q_id'] == qid]['answer'].values[0]
        return {
            "q_id": qid, "input": q_text, "actual_output": answer, 
            "expected_output": golden, "retrieval_context": "|".join(contexts)
        }

    with ThreadPoolExecutor(max_workers=2) as executor:
        rag_results = list(executor.map(run_rag, [row for _, row in df_q.iterrows()]))

    pd.DataFrame(rag_results).to_csv(TEMP_CSV, index=False, encoding="utf-8-sig")
    print(f"âœ… éšæ®µ 1 å®Œæˆï¼Œä¸­é–“çµæœå·²å­˜è‡³ {TEMP_CSV}")

    # --- C. ç¬¬äºŒéšæ®µï¼šè®€å– CSV é€²è¡Œè©•ä¼° ---
    print(f"\nğŸ§ éšæ®µ 2ï¼šé–‹å§‹ DeepEval å“è³ªè©•ä¼°æŒ‡æ¨™åˆ†æ...")
    df_eval = pd.read_csv(TEMP_CSV)
    
    metrics = [
        FaithfulnessMetric(model=custom_llm, async_mode=False),
        AnswerRelevancyMetric(model=custom_llm, async_mode=False),
        ContextualRecallMetric(model=custom_llm, async_mode=False),
        ContextualPrecisionMetric(model=custom_llm, async_mode=False),
        ContextualRelevancyMetric(model=custom_llm, async_mode=False)
    ]

    final_scores = []
    for _, row in df_eval.iterrows():
        print(f"æ­£åœ¨è©•ä¼° Q{row['q_id']}...")
        contexts = row['retrieval_context'].split("|")
        
        test_case = LLMTestCase(
            input=row['input'],
            actual_output=row['actual_output'],
            expected_output=row['expected_output'],
            retrieval_context=contexts
        )
        
        res_dict = row.to_dict()
        for m in metrics:
            m.measure(test_case)
            res_dict[m.__class__.__name__] = m.score
        
        final_scores.append(res_dict)

    # --- D. å„²å­˜çµæœ ---
    pd.DataFrame(final_scores).sort_values("q_id").to_csv(FINAL_CSV, index=False, encoding="utf-8-sig")
    print(f"\nğŸ‰ ä»»å‹™åœ“æ»¿å®Œæˆï¼æœ€çµ‚è©•åˆ†å ±è¡¨ï¼š{FINAL_CSV}")

if __name__ == "__main__":
    main()