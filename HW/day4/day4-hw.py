import os
import json
import base64
import requests
from typing import TypedDict, List, Annotated
import operator
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END
from playwright.sync_api import sync_playwright

# --- 1. Áí∞Â¢ÉË®≠ÂÆö ---
SEARXNG_URL = "https://puli-8080.huannago.com/search"
CACHE_FILE = "qa_cache.json"

<<<<<<< HEAD
# ‰ΩøÁî® Gemma-3-27b ÈÄ≤Ë°åÊé®ÁêÜ
=======
>>>>>>> d58df6c9950b4dfedc1ac4da9750b392a19019ce
llm = ChatOpenAI(
    base_url="https://ws-05.huannago.com/v1",
    api_key="YOUR_API_KEY", 
    model="google/gemma-3-27b-it",
    temperature=0 
)

# --- 2. ÁãÄÊÖãÂÆöÁæ© ---
class State(TypedDict):
    input_query: str
    knowledge_base: str
    keywords: List[str]
    search_links: List[dict]
    visited_urls: Annotated[List[str], operator.add]
    final_answer: str
    is_sufficient: bool 
    loop_count: int

# --- 3. Ê†∏ÂøÉÂ∑•ÂÖ∑ ---
def internal_vlm_read_website(url: str, original_query: str) -> str:
<<<<<<< HEAD
    """ÈÄèÈÅé Playwright Êà™Âúñ‰∏¶ËÆì VLM ÂàÜÊûêÁ∂≤È†Å‰∫ãÂØ¶"""
=======
>>>>>>> d58df6c9950b4dfedc1ac4da9750b392a19019ce
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            page = browser.new_page()
            page.set_viewport_size({"width": 1280, "height": 900})
<<<<<<< HEAD
            # Á≠âÂæÖÁ∂≤Ë∑ØÈñíÁΩÆÔºåÁ¢∫‰øùÂúñÁâáËàáË°®Ê†ºËºâÂÖ•
            page.goto(url, wait_until="networkidle", timeout=30000)
            page.wait_for_timeout(2000)
            b64 = base64.b64encode(page.screenshot(full_page=False)).decode('utf-8')
            browser.close()
            
            msg = [
                {"type": "text", "text": f"""‰Ω†ÊòØ‰∏Ä‰Ωç‰∫ãÂØ¶ÂàÜÊûêÂÆò„ÄÇË´ãÈáùÂ∞çÂïèÈ°å„Äå{original_query}„ÄçÂàÜÊûêÁ∂≤È†ÅÊà™ÂúñÔºö
                1. **Ê†∏ÂøÉ‰∫ãÂØ¶**ÔºöÊèêÂèñËàáÂïèÈ°åÁõ¥Êé•Áõ∏ÈóúÁöÑÊôÇÈñì„ÄÅÊï∏Êìö„ÄÅËÅ≤ÊòéÂéüÊñá„ÄÇ
                2. **‰æÜÊ∫ê‰ø°Â∫¶**ÔºöÂà§Êñ∑Ê≠§ÁÇ∫ÂÆòÊñπÂÖ¨Âëä„ÄÅÂ™íÈ´îÂ†±Â∞éÊàñÂÄã‰∫∫Ë©ïË´ñ„ÄÇ
                3. **Á¥∞ÁØÄÊäìÂèñ**ÔºöËã•ÊúâË°®Ê†ºÊàñÁ¥∞ÂâáÔºåË´ãÁ≤æÁ¢∫ÂàóÂá∫„ÄÇ
                Â¶ÇÊûúÁ∂≤È†ÅÂÖßÂÆπÂÆåÂÖ®ÁÑ°ÈóúÔºåË´ãÂõûË¶Ü„ÄåÁÑ°Áõ∏ÈóúË≥áË®ä„Äç„ÄÇ"""},
=======
            page.goto(url, wait_until="domcontentloaded", timeout=30000)
            page.wait_for_timeout(3000)
            b64 = base64.b64encode(page.screenshot()).decode('utf-8')
            browser.close()
            
            msg = [
                {"type": "text", "text": f"""‰Ω†ÊòØ‰∏Ä‰Ωç‰∫ãÂØ¶ÂàÜÊûêÂÆò„ÄÇË´ãÈáùÂ∞çÁî®Êà∂ÁöÑÂïèÈ°å„Äå{original_query}„ÄçÂàÜÊûêÊ≠§Á∂≤È†ÅÊà™ÂúñÔºö
                1. **‰æÜÊ∫êÊÄßË≥™**ÔºöË©≤Á∂≤È†ÅÊòØÂê¶ÁÇ∫ÂÆòÊñπÁôºÂ∏É„ÄÅÊ¨äÂ®ÅÂ†±Â∞éÊàñ‰∏ÄËà¨Á§æÁæ§Ë®éË´ñÔºü
                2. **Ê†∏ÂøÉ‰∫ãÂØ¶**ÔºöÊèêÂèñÊâÄÊúâËàáÂïèÈ°åÁõ∏ÈóúÁöÑÊôÇÈñì„ÄÅÊï∏ÊìöÊàñ‰∫ã‰ª∂ÁãÄÊÖã„ÄÇ
                3. **ËÆäÂåñË®òÈåÑ**ÔºöËã•ÂïèÈ°åÊ∂âÂèäËÆäÂãïÔºåË´ãÁ≤æÁ¢∫Ë®òÈåÑ„ÄåËÆäÂãïÂâç„ÄçËàá„ÄåËÆäÂãïÂæå„ÄçÁöÑÂÖ∑È´îÂÖßÂÆπ„ÄÇ
                4. **ÂèØ‰ø°Â∫¶**ÔºöÂÖßÂÆπ‰∏≠ÊòØÂê¶ÊúâÊ®ôË®ª„ÄéÂÇ≥ËÅû„Äè„ÄÅ„ÄéÁåúÊ∏¨„ÄèÊàñ„ÄéÈùûÂÆòÊñπË≠âÂØ¶„ÄèÁ≠âÂ≠óÁúºÔºü"""},
>>>>>>> d58df6c9950b4dfedc1ac4da9750b392a19019ce
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64}"}}
            ]
            res = llm.invoke([HumanMessage(content=msg)])
            return res.content
<<<<<<< HEAD
    except Exception as e: 
        return f"ËÆÄÂèñÈåØË™§: {str(e)}"

# --- 4. ÊµÅÁ®ãÁØÄÈªûÂØ¶Áèæ ---
=======
    except Exception as e: return f"ËÆÄÂèñÈåØË™§: {e}"

# --- 4. ÊµÅÁ®ãÁØÄÈªûÂØ¶Áèæ (ÂÆåÂÖ®‰∏çÂê´Ê®ôÁöÑË≥áË®ä) ---
>>>>>>> d58df6c9950b4dfedc1ac4da9750b392a19019ce

def check_cache_node(state: State):
    print(f"üîé [Ê≠•È©ü 1] Ê™¢Êü•Âø´Âèñ...")
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            cache = json.load(f)
            if state['input_query'] in cache:
<<<<<<< HEAD
                print("üéØ [ÂëΩ‰∏≠Âø´Âèñ] ËºâÂÖ•ÁèæÊúâÊü•Ë≠âÂ†±Âëä„ÄÇ")
=======
                print("üéØ [ÂëΩ‰∏≠Âø´Âèñ]")
>>>>>>> d58df6c9950b4dfedc1ac4da9750b392a19019ce
                return {"final_answer": cache[state['input_query']]}
    return {"knowledge_base": "", "loop_count": 0, "visited_urls": []}

def planner_node(state: State):
<<<<<<< HEAD
    if state['loop_count'] >= 5: 
        print("üö® [Á≥ªÁµ±] Â∑≤ÈÅîÊúÄÂ§ßËº™Ê¨°‰∏äÈôêÔºåÂº∑Âà∂ÁµêÊùüË™øÊü•„ÄÇ")
        return {"is_sufficient": True}

    print(f"\nüïµÔ∏è [Ê≠•È©ü 2] ÊåáÊèÆÂÆò (Planner) Ë©ï‰º∞ (Ëº™Ê¨° {state['loop_count']})...")
    
    prompt = f"""
    ‰Ω†ÊòØ‰∏Ä‰ΩçÂö¥Ë¨πÁöÑ‰∫ãÂØ¶ÂØ©Ê†∏ÊåáÊèÆÂÆò„ÄÇË´ãÊ†πÊìöÁõÆÂâçÊéåÊè°ÁöÑË≠âÊìöË©ï‰º∞ÊòØÂê¶Â∑≤Ë∂≥Â§†ÂõûÁ≠îÁî®Êà∂ÂïèÈ°å„ÄÇ
    
    „ÄêÁî®Êà∂ÂïèÈ°å„ÄëÔºö{state['input_query']}
    „ÄêÁõÆÂâçË≠âÊìöÂ∫´„ÄëÔºö{state['knowledge_base'][-2000:]}

    Âà§Êñ∑Ê∫ñÂâáÔºö
    1. ÈóúÈçµ‰∫ãÂØ¶ÔºàÂ¶ÇÊó•Êúü„ÄÅÊï∏ÂÄº„ÄÅÂãï‰Ωú‰∏ªÈ´îÔºâÊòØÂê¶ÊòéÁ¢∫Ôºü
    2. ÊòØÂê¶ÊúâÂÆòÊñπ‰æÜÊ∫êËÉåÊõ∏Ôºü
    3. Â§öÂÄãÁ∂≤È†ÅÈñìÊòØÂê¶ÊúâË≥áË®äË°ùÁ™ÅÔºü

    Ëã•Â∑≤Ë∂≥Â§†ÔºåÂõûÂÇ≥ [COMPLETE]„ÄÇ
    Ëã•ÈúÄÊõ¥Â§öÁ¥∞ÁØÄÔºåÂõûÂÇ≥ [CONTINUE] ‰∏¶ÂÖ∑È´îÊèèËø∞„ÄåÈÇÑÁº∫‰ªÄÈ∫ºË≥áË®ä„Äç„ÄÇ
    """
    
    res = llm.invoke([HumanMessage(content=prompt)])
    content = res.content.upper()
    is_sufficient = "[COMPLETE]" in content

    print(f"üìù Ë©ï‰º∞Â†±ÂëäÔºö{'‚úÖ Ë≥áË®äÂ∑≤ÂÆåÊï¥' if is_sufficient else f'‚ùå ÈúÄÁπºÁ∫åË™øÊü•„ÄÇÁº∫Âè£Ôºö{content}'}")
    return {"is_sufficient": is_sufficient}

def query_gen_node(state: State):
    print(f"\nüí° [Ê≠•È©ü 3] Á≠ñÁï•ÂÆò (Query Gen) Ê≠£Âú®ÂàÜÊûêËàá‰øÆÊ≠£Á≠ñÁï•...")
    
    past_kws = state.get('keywords', [])
    knowledge = state.get('knowledge_base', '')

    prompt = f"""
    ‰Ω†ÊòØ‰∏Ä‰ΩçÊÉÖÂ†±ÊêúÂ∞ãÂ∞àÂÆ∂„ÄÇË´ãÁîüÊàê‰∏ÄÂÄãÁ≤æÊ∫ñÁöÑËã±ÊñáÊêúÂ∞ãË©ûÔºå‰ª•Â°´Ë£úÁõÆÂâçÊü•Ë≠âÁöÑË≥áË®äÁº∫Âè£„ÄÇ
    
    „ÄêÁî®Êà∂ÂïèÈ°å„ÄëÔºö{state['input_query']}
    „ÄêÂ∑≤Ë©¶ÈÅéÈóúÈçµÂ≠ó„ÄëÔºö{", ".join(past_kws) if past_kws else "ÁÑ°"}
    „ÄêÊü•Ë≠âÈÄ≤Â∫¶ÊëòË¶Å„ÄëÔºö{knowledge[:400] if knowledge else "Â∞öÊú™Áç≤ÂæóÊúâÊïàË≥áË®ä"}

    Ë¶èÂâáÔºö
    1. ÈÅøÂÖçÈáçË§áÂ∑≤‰ΩøÁî®ÁöÑË©û„ÄÇ
    2. ÁîüÊàêÊõ¥ÂÖ∑È´î„ÄÅÊúùÂêë„ÄåÂÆòÊñπÂÖ¨Âëä„ÄçÊàñ„ÄåÂéüÂßãÊñá‰ª∂„ÄçÁöÑÊêúÂ∞ãË©û„ÄÇ
    3. ÂÉÖÂõûÂÇ≥ÈóúÈçµÂ≠óÂ≠ó‰∏≤Ôºå‰∏çÈúÄËß£Èáã„ÄÇ
    """
    
    res = llm.invoke([HumanMessage(content=prompt)])
    new_kw = res.content.strip().replace('"', '').replace('*', '')
    
    print(f"üöÄ Êñ∞ÁîüÊàêÁöÑÁ≤æÊ∫ñÈóúÈçµÂ≠óÔºö„Äê {new_kw} „Äë")
    return {"keywords": state.get('keywords', []) + [new_kw]}

def search_node(state: State):
    current_kw = state['keywords'][-1]
    print(f"üì° [Ê≠•È©ü 4] Ê™¢Á¥¢‰∏≠Ôºö{current_kw}...")
    try:
        r = requests.get(SEARXNG_URL, params={"q": current_kw, "format": "json"}, timeout=15).json()
        raw_results = r.get('results', [])
        # ÈÅéÊøæÂ∑≤ÈÄ†Ë®™Á∂≤ÂùÄ
        filtered = [res for res in raw_results if res['url'] not in state['visited_urls']]
        return {"search_links": filtered[:3]} # ÊèêÂèñÂâç 3 ÁØá‰æõ VLM Èñ±ËÆÄ
    except:
        return {"search_links": []}

def vlm_and_value_node(state: State):
    links = state.get('search_links', [])
    print(f"üì∏ [Ê≠•È©ü 5] VLM ‰∫ãÂØ¶ÊèêÂèñ (È†êË®àÊéÉÊèè {len(links)} ÁØáÊñáÁ´†)...")
    
    new_info_batch = ""
    newly_visited = []
    
    for i, link in enumerate(links):
        url = link['url']
        print(f"üìñ [{i+1}/{len(links)}] Ê≠£Âú®Ë¶ñË¶∫ÂåñÊéÉÊèèÔºö{url[:50]}...")
        
        info = internal_vlm_read_website(url, state['input_query'])
        
        if "ÁÑ°Áõ∏ÈóúË≥áË®ä" not in info:
            new_info_batch += f"\n[‰æÜÊ∫ê {state['loop_count']+1}-{i+1}]: {url}\n{info}\n"
        
        newly_visited.append(url)
        
    return {
        "knowledge_base": state['knowledge_base'] + new_info_batch, 
        "visited_urls": newly_visited, 
        "loop_count": state['loop_count'] + 1
    }

def output_node(state: State):
    if state.get("final_answer"): return state
    print("\nüèÅ [Ê≠•È©ü 6] ÂΩôÊï¥ÊúÄÁµÇÊü•Ë≠âÂ†±Âëä...")
    
    prompt = f"""ÈáùÂ∞çÂïèÈ°å„Äå{state['input_query']}„ÄçÔºåË´ãÊ†πÊìö‰ª•‰∏ãË™øÊü•‰∫ãÂØ¶Êí∞ÂØ´‰∏Ä‰ªΩÂö¥Ë¨πÁöÑÂ†±Âëä„ÄÇ
    
    „Äê‰∫ãÂØ¶Â∫´„ÄëÔºö
    {state['knowledge_base']}

    Ê†ºÂºèË¶ÅÊ±ÇÔºö
    1. **ÁµêË´ñÂÖàË°å**ÔºöÁõ¥Êé•ÂõûÁ≠îÊü•Ë≠âÁµêÊûú„ÄÇ
    2. **Ë≠âÊìöÂàóË°®**ÔºöÂàóÂá∫ÊîØÊåÅ‰∫ãÂØ¶ÁöÑÂÆòÊñπ‰æÜÊ∫êËàáÂÖ∑È´îÊï∏Êìö„ÄÇ
    3. **Áà≠Ë≠∞Èªû/Áº∫Â§±**ÔºöËã•ÊúâÁüõÁõæÊàñÊü•‰∏çÂà∞ÁöÑÈÉ®ÂàÜÔºåË´ãÂ¶ÇÂØ¶Ë™™Êòé„ÄÇ
    """
=======
    if state['loop_count'] >= 5: return {"is_sufficient": True}

    print(f"üß† [Ê≠•È©ü 2] Ê±∫Á≠ñË©ï‰º∞ (Á¨¨ {state['loop_count']} Ëº™)...")
    prompt = f"""Áî®Êà∂ÂïèÈ°åÔºö{state['input_query']}
    Áï∂ÂâçÊî∂ÈõÜË≥áË®äÔºö{state['knowledge_base']}
    
    Ë´ãÂà§Êñ∑Ôºö
    1. Ë≥áË®äÊòØÂê¶ÂåÖÂê´‰æÜËá™ÂÆòÊñπ‰∏ªÈ´îÔºàÁõ∏ÈóúÂÖ¨Âè∏/Ê©üÊßãÔºâÁöÑÁõ¥Êé•Ë≠âÊìöÔºü
    2. Â¶ÇÊûúÂïèÈ°åÊ∂âÂèäÊ¨°Êï∏Ë®àÁÆóÔºåÊòØÂê¶ÊúâÊòéÁ¢∫ÁöÑËÆäÂåñÊ≠∑Á®ãË®òÈåÑÔºü
    3. ÊòØÂê¶ÊúâË∂≥Â§†Ë≠âÊìöÊéíÈô§Á¨¨‰∏âÊñπÂ™íÈ´îÁöÑÁåúÊ∏¨Ôºü
    
    Ë≥áË®äÊòØÂê¶ÂÖÖË£ïÔºüË´ãÂõûÁ≠î y Êàñ n„ÄÇ"""
    
    res = llm.invoke([HumanMessage(content=prompt)])
    return {"is_sufficient": 'y' in res.content.lower()}

def query_gen_node(state: State):
    print("üí° [Ê≠•È©ü 3] ÂãïÊÖãÁîüÊàêÊêúÂ∞ãÁ≠ñÁï•...")
    # ÂÆåÂÖ®Ê†πÊìöÁî®Êà∂Ëº∏ÂÖ•ÂãïÊÖãÁîüÊàêÊêúÂ∞ãË©û
    prompt = f"Ê†πÊìöÂïèÈ°å„Äå{state['input_query']}„ÄçÔºåË´ãÁîüÊàê‰∏ÄÂÄãÊúÄËÉΩÊâæÂà∞„ÄåÂÆòÊñπÂéüÂßãÂÖ¨Âëä„ÄçÊàñ„ÄåÊ¨äÂ®ÅÊï∏Êìö„ÄçÁöÑËã±ÊñáÊêúÂ∞ãÈóúÈçµÂ≠ó„ÄÇÂè™ÈúÄÂõûÂÇ≥ÈóúÈçµÂ≠óÂ≠ó‰∏≤„ÄÇ"
    res = llm.invoke([HumanMessage(content=prompt)])
    new_kw = res.content.strip().replace('"', '')
    print(f"üìå ÊêúÂ∞ãÈóúÈçµÂ≠óÔºö{new_kw}")
    return {"keywords": state.get('keywords', []) + [new_kw]}

def search_node(state: State):
    print(f"üì° [Ê≠•È©ü 4] Ê™¢Á¥¢Á∂≤Ë∑ØË≥áÊ∫ê...")
    try:
        r = requests.get(SEARXNG_URL, params={"q": state['keywords'][-1], "format": "json"}, timeout=15).json()
        return {"search_links": r.get('results', [])[:3]}
    except: return {"search_links": []}

def vlm_and_value_node(state: State):
    print("üì∏ [Ê≠•È©ü 5] VLM ‰∫ãÂØ¶ÊèêÂèñ...")
    links = state.get('search_links', [])
    new_info = ""
    for link in links:
        if link['url'] in state['visited_urls']: continue
        print(f"üìñ Èñ±ËÆÄ‰æÜÊ∫êÔºö{link['url'][:50]}...")
        info = internal_vlm_read_website(link['url'], state['input_query'])
        new_info += f"\n[‰æÜÊ∫ê: {link['url']}]\n{info}\n"
        break 
    return {"knowledge_base": state['knowledge_base'] + new_info, "visited_urls": [link['url']], "loop_count": state['loop_count'] + 1}

def output_node(state: State):
    if state.get("final_answer"): return state
    print("üèÅ [Ê≠•È©ü 6] ÂΩôÊï¥ÊúÄÁµÇ‰∫ãÂØ¶Â†±Âëä...")
    prompt = f"""Ë´ãÈáùÂ∞çÁî®Êà∂ÂïèÈ°å„Äå{state['input_query']}„ÄçÁî¢Âá∫Êü•Ë≠âÂ†±Âëä„ÄÇ
    
    „ÄêË¶èÂâá„ÄëÔºö
    1. **Ë≠âÊìöÂàÜÁ¥ö**ÔºöÂÑ™ÂÖàÊé°Áî®ÂÆòÊñπ‰∏ªÈ´îÁöÑÁõ¥Êé•Ë≠âÊìöÔºåÊéíÈô§Êú™Á∂ìË≠âÂØ¶ÁöÑÂÇ≥ËÅû„ÄÇ
    2. **ËÆäÂåñÊ†∏Â∞ç**ÔºöÂ¶ÇÊûúÊ∂âÂèäËÆäÂãïÊ¨°Êï∏ÔºåË´ãÂàóÂá∫ÂÖ∑È´îÁöÑÊôÇÈñìËª∏ÁØÄÈªû„ÄÇ
    3. **Ë™†ÂØ¶ÊÄß**ÔºöËã•Ë≠âÊìö‰∏çË∂≥ÔºåË´ãÂ¶ÇÂØ¶Ë™™ÊòéÂì™‰∫õÈÉ®ÂàÜÂ±¨ÊñºÂÆòÊñπÁ¢∫ÂÆöÔºåÂì™‰∫õÂ±¨ÊñºÂ™íÈ´îÊé®Ê∏¨„ÄÇ
    
    Á≠ÜË®òÂÖßÂÆπÔºö
    {state['knowledge_base']}"""
>>>>>>> d58df6c9950b4dfedc1ac4da9750b392a19019ce
    
    res = llm.invoke([HumanMessage(content=prompt)])
    final_ans = res.content
    
    # Âø´ÂèñËôïÁêÜ
    try:
        if not os.path.exists(CACHE_FILE): cache = {}
        else:
            with open(CACHE_FILE, "r", encoding="utf-8") as f: cache = json.load(f)
        cache[state['input_query']] = final_ans
        with open(CACHE_FILE, "w", encoding="utf-8") as f: json.dump(cache, f, ensure_ascii=False, indent=4)
    except: pass
    
    return {"final_answer": final_ans}

# --- 5. ÊßãÂª∫ÂúñË°® ---
<<<<<<< HEAD
=======



>>>>>>> d58df6c9950b4dfedc1ac4da9750b392a19019ce
workflow = StateGraph(State)
workflow.add_node("check_cache", check_cache_node)
workflow.add_node("planner", planner_node)
workflow.add_node("query_gen", query_gen_node)
workflow.add_node("search_tool", search_node)
workflow.add_node("vlm_process", vlm_and_value_node)
workflow.add_node("output", output_node)

workflow.set_entry_point("check_cache")
workflow.add_conditional_edges("check_cache", lambda x: "hit" if x.get("final_answer") else "miss", {"hit": "output", "miss": "planner"})
workflow.add_conditional_edges("planner", lambda x: "y" if x["is_sufficient"] else "n", {"y": "output", "n": "query_gen"})
workflow.add_edge("query_gen", "search_tool")
workflow.add_edge("search_tool", "vlm_process")
workflow.add_edge("vlm_process", "planner")
workflow.add_edge("output", END)

app = workflow.compile()

# --- 6. Âü∑Ë°å‰ªãÈù¢ ---
if __name__ == "__main__":
<<<<<<< HEAD
    print("\nüïµÔ∏è Ê∑±Â∫¶‰∫ãÂØ¶Êü•Ë≠âÂºïÊìéÂïüÂãï...")
    while True:
        print(app.get_graph().print_ascii())
        user_input = input("\nüîé Ë´ãËº∏ÂÖ•Ë¶ÅÊü•Ë≠âÁöÑÂïèÈ°å (exit ÈÄÄÂá∫)Ôºö").strip()
        if not user_input or user_input.lower() == 'exit': break
        
=======
    print("\n" + "="*50)
    print("üïµÔ∏è ÈÄöÁî®ÂûãËá™Âæã‰∫ãÂØ¶Êü•Ë≠âÂºïÊìé (Ê®ôÁöÑÂéª‰∏≠ÂøÉÂåñÁâà)")
    try: app.get_graph().print_ascii()
    except: pass
    print("="*50)

    while True:
        user_input = input("\nüîé Ë´ãËº∏ÂÖ•Ë¶ÅÊü•Ë≠âÁöÑÂïèÈ°å (exit ÈÄÄÂá∫)Ôºö").strip()
        if not user_input or user_input.lower() == 'exit': break
        
        # Âü∑Ë°å‰∏¶È°ØÁ§∫ÈÅéÁ®ã
>>>>>>> d58df6c9950b4dfedc1ac4da9750b392a19019ce
        result = app.invoke({
            "input_query": user_input, 
            "knowledge_base": "", 
            "keywords": [], 
            "loop_count": 0, 
            "final_answer": "", 
            "visited_urls": []
        })
        
<<<<<<< HEAD
        print("\n" + "‚òÖ"*35)
        print("‚ú® „Äê ÊúÄÁµÇÊü•Ë≠âÂ†±Âëä „Äë")
        print(result['final_answer'])
        print(f"üìä Ë™øÊü•Áµ±Ë®àÔºöÊ≠∑Á∂ì {result['loop_count']} Ëº™Ë™øÊü•ÔºåÂÖ±ÊéÉÊèè {len(result['visited_urls'])} ÂÄãÁ∂≤È†Å")
        print("‚òÖ"*35)
=======
        print("\n" + "‚òÖ"*25)
        print("‚ú® „Äê Êü• Ë≠â Â†± Âëä „Äë")
        print(result['final_answer'])
        print(f"üìä Ë™øÊü•Ê∑±Â∫¶Ôºö{result['loop_count']} Ëº™")
        print("‚òÖ"*25)
>>>>>>> d58df6c9950b4dfedc1ac4da9750b392a19019ce
