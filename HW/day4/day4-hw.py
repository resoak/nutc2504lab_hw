import os
import json
import base64
import requests
from typing import TypedDict, List, Annotated
import operator
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END
from playwright.sync_api import sync_playwright

# --- 1. ç’°å¢ƒè¨­å®š ---
SEARXNG_URL = "https://puli-8080.huannago.com/search"
CACHE_FILE = "qa_cache.json"

# ä½¿ç”¨ Gemma-3-27b é€²è¡Œæ¨ç†
llm = ChatOpenAI(
    base_url="https://ws-05.huannago.com/v1",
    api_key="YOUR_API_KEY", 
    model="google/gemma-3-27b-it",
    temperature=0 
)

# --- 2. ç‹€æ…‹å®šç¾© ---
class State(TypedDict):
    input_query: str
    knowledge_base: str
    keywords: List[str]
    search_links: List[dict]
    visited_urls: Annotated[List[str], operator.add]
    final_answer: str
    is_sufficient: bool 
    loop_count: int

# --- 3. æ ¸å¿ƒå·¥å…· ---
def internal_vlm_read_website(url: str, original_query: str) -> str:
    """é€é Playwright æˆªåœ–ä¸¦è®“ VLM åˆ†æç¶²é äº‹å¯¦"""
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            page = browser.new_page()
            page.set_viewport_size({"width": 1280, "height": 900})
            # ç­‰å¾…ç¶²è·¯é–’ç½®ï¼Œç¢ºä¿åœ–ç‰‡èˆ‡è¡¨æ ¼è¼‰å…¥
            page.goto(url, wait_until="networkidle", timeout=30000)
            page.wait_for_timeout(2000)
            b64 = base64.b64encode(page.screenshot(full_page=False)).decode('utf-8')
            browser.close()
            
            msg = [
                {"type": "text", "text": f"""ä½ æ˜¯ä¸€ä½äº‹å¯¦åˆ†æå®˜ã€‚è«‹é‡å°å•é¡Œã€Œ{original_query}ã€åˆ†æç¶²é æˆªåœ–ï¼š
                1. **æ ¸å¿ƒäº‹å¯¦**ï¼šæå–èˆ‡å•é¡Œç›´æ¥ç›¸é—œçš„æ™‚é–“ã€æ•¸æ“šã€è²æ˜åŸæ–‡ã€‚
                2. **ä¾†æºä¿¡åº¦**ï¼šåˆ¤æ–·æ­¤ç‚ºå®˜æ–¹å…¬å‘Šã€åª’é«”å ±å°æˆ–å€‹äººè©•è«–ã€‚
                3. **ç´°ç¯€æŠ“å–**ï¼šè‹¥æœ‰è¡¨æ ¼æˆ–ç´°å‰‡ï¼Œè«‹ç²¾ç¢ºåˆ—å‡ºã€‚
                å¦‚æœç¶²é å…§å®¹å®Œå…¨ç„¡é—œï¼Œè«‹å›è¦†ã€Œç„¡ç›¸é—œè³‡è¨Šã€ã€‚"""},
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64}"}}
            ]
            res = llm.invoke([HumanMessage(content=msg)])
            return res.content
    except Exception as e: 
        return f"è®€å–éŒ¯èª¤: {str(e)}"

# --- 4. æµç¨‹ç¯€é»å¯¦ç¾ ---

def check_cache_node(state: State):
    print(f"ğŸ” [æ­¥é©Ÿ 1] æª¢æŸ¥å¿«å–...")
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            cache = json.load(f)
            if state['input_query'] in cache:
                print("ğŸ¯ [å‘½ä¸­å¿«å–] è¼‰å…¥ç¾æœ‰æŸ¥è­‰å ±å‘Šã€‚")
                return {"final_answer": cache[state['input_query']]}
    return {"knowledge_base": "", "loop_count": 0, "visited_urls": []}

def planner_node(state: State):
    if state['loop_count'] >= 5: 
        print("ğŸš¨ [ç³»çµ±] å·²é”æœ€å¤§è¼ªæ¬¡ä¸Šé™ï¼Œå¼·åˆ¶çµæŸèª¿æŸ¥ã€‚")
        return {"is_sufficient": True}

    print(f"\nğŸ•µï¸ [æ­¥é©Ÿ 2] æŒ‡æ®å®˜ (Planner) è©•ä¼° (è¼ªæ¬¡ {state['loop_count']})...")
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä½åš´è¬¹çš„äº‹å¯¦å¯©æ ¸æŒ‡æ®å®˜ã€‚è«‹æ ¹æ“šç›®å‰æŒæ¡çš„è­‰æ“šè©•ä¼°æ˜¯å¦å·²è¶³å¤ å›ç­”ç”¨æˆ¶å•é¡Œã€‚
    
    ã€ç”¨æˆ¶å•é¡Œã€‘ï¼š{state['input_query']}
    ã€ç›®å‰è­‰æ“šåº«ã€‘ï¼š{state['knowledge_base'][-2000:]}

    åˆ¤æ–·æº–å‰‡ï¼š
    1. é—œéµäº‹å¯¦ï¼ˆå¦‚æ—¥æœŸã€æ•¸å€¼ã€å‹•ä½œä¸»é«”ï¼‰æ˜¯å¦æ˜ç¢ºï¼Ÿ
    2. æ˜¯å¦æœ‰å®˜æ–¹ä¾†æºèƒŒæ›¸ï¼Ÿ
    3. å¤šå€‹ç¶²é é–“æ˜¯å¦æœ‰è³‡è¨Šè¡çªï¼Ÿ

    è‹¥å·²è¶³å¤ ï¼Œå›å‚³ [COMPLETE]ã€‚
    è‹¥éœ€æ›´å¤šç´°ç¯€ï¼Œå›å‚³ [CONTINUE] ä¸¦å…·é«”æè¿°ã€Œé‚„ç¼ºä»€éº¼è³‡è¨Šã€ã€‚
    """
    
    res = llm.invoke([HumanMessage(content=prompt)])
    content = res.content.upper()
    is_sufficient = "[COMPLETE]" in content

    print(f"ğŸ“ è©•ä¼°å ±å‘Šï¼š{'âœ… è³‡è¨Šå·²å®Œæ•´' if is_sufficient else f'âŒ éœ€ç¹¼çºŒèª¿æŸ¥ã€‚ç¼ºå£ï¼š{content}'}")
    return {"is_sufficient": is_sufficient}

def query_gen_node(state: State):
    print(f"\nğŸ’¡ [æ­¥é©Ÿ 3] ç­–ç•¥å®˜ (Query Gen) æ­£åœ¨åˆ†æèˆ‡ä¿®æ­£ç­–ç•¥...")
    
    past_kws = state.get('keywords', [])
    knowledge = state.get('knowledge_base', '')

    prompt = f"""
    ä½ æ˜¯ä¸€ä½æƒ…å ±æœå°‹å°ˆå®¶ã€‚è«‹ç”Ÿæˆä¸€å€‹ç²¾æº–çš„è‹±æ–‡æœå°‹è©ï¼Œä»¥å¡«è£œç›®å‰æŸ¥è­‰çš„è³‡è¨Šç¼ºå£ã€‚
    
    ã€ç”¨æˆ¶å•é¡Œã€‘ï¼š{state['input_query']}
    ã€å·²è©¦éé—œéµå­—ã€‘ï¼š{", ".join(past_kws) if past_kws else "ç„¡"}
    ã€æŸ¥è­‰é€²åº¦æ‘˜è¦ã€‘ï¼š{knowledge[:400] if knowledge else "å°šæœªç²å¾—æœ‰æ•ˆè³‡è¨Š"}

    è¦å‰‡ï¼š
    1. é¿å…é‡è¤‡å·²ä½¿ç”¨çš„è©ã€‚
    2. ç”Ÿæˆæ›´å…·é«”ã€æœå‘ã€Œå®˜æ–¹å…¬å‘Šã€æˆ–ã€ŒåŸå§‹æ–‡ä»¶ã€çš„æœå°‹è©ã€‚
    3. åƒ…å›å‚³é—œéµå­—å­—ä¸²ï¼Œä¸éœ€è§£é‡‹ã€‚
    """
    
    res = llm.invoke([HumanMessage(content=prompt)])
    new_kw = res.content.strip().replace('"', '').replace('*', '')
    
    print(f"ğŸš€ æ–°ç”Ÿæˆçš„ç²¾æº–é—œéµå­—ï¼šã€ {new_kw} ã€‘")
    return {"keywords": state.get('keywords', []) + [new_kw]}

def search_node(state: State):
    current_kw = state['keywords'][-1]
    print(f"ğŸ“¡ [æ­¥é©Ÿ 4] æª¢ç´¢ä¸­ï¼š{current_kw}...")
    try:
        r = requests.get(SEARXNG_URL, params={"q": current_kw, "format": "json"}, timeout=15).json()
        raw_results = r.get('results', [])
        # éæ¿¾å·²é€ è¨ªç¶²å€
        filtered = [res for res in raw_results if res['url'] not in state['visited_urls']]
        return {"search_links": filtered[:3]} # æå–å‰ 3 ç¯‡ä¾› VLM é–±è®€
    except:
        return {"search_links": []}

def vlm_and_value_node(state: State):
    links = state.get('search_links', [])
    print(f"ğŸ“¸ [æ­¥é©Ÿ 5] VLM äº‹å¯¦æå– (é è¨ˆæƒæ {len(links)} ç¯‡æ–‡ç« )...")
    
    new_info_batch = ""
    newly_visited = []
    
    for i, link in enumerate(links):
        url = link['url']
        print(f"ğŸ“– [{i+1}/{len(links)}] æ­£åœ¨è¦–è¦ºåŒ–æƒæï¼š{url[:50]}...")
        
        info = internal_vlm_read_website(url, state['input_query'])
        
        if "ç„¡ç›¸é—œè³‡è¨Š" not in info:
            new_info_batch += f"\n[ä¾†æº {state['loop_count']+1}-{i+1}]: {url}\n{info}\n"
        
        newly_visited.append(url)
        
    return {
        "knowledge_base": state['knowledge_base'] + new_info_batch, 
        "visited_urls": newly_visited, 
        "loop_count": state['loop_count'] + 1
    }

def output_node(state: State):
    if state.get("final_answer"): return state
    print("\nğŸ [æ­¥é©Ÿ 6] å½™æ•´æœ€çµ‚æŸ¥è­‰å ±å‘Š...")
    
    prompt = f"""é‡å°å•é¡Œã€Œ{state['input_query']}ã€ï¼Œè«‹æ ¹æ“šä»¥ä¸‹èª¿æŸ¥äº‹å¯¦æ’°å¯«ä¸€ä»½åš´è¬¹çš„å ±å‘Šã€‚
    
    ã€äº‹å¯¦åº«ã€‘ï¼š
    {state['knowledge_base']}

    æ ¼å¼è¦æ±‚ï¼š
    1. **çµè«–å…ˆè¡Œ**ï¼šç›´æ¥å›ç­”æŸ¥è­‰çµæœã€‚
    2. **è­‰æ“šåˆ—è¡¨**ï¼šåˆ—å‡ºæ”¯æŒäº‹å¯¦çš„å®˜æ–¹ä¾†æºèˆ‡å…·é«”æ•¸æ“šã€‚
    3. **çˆ­è­°é»/ç¼ºå¤±**ï¼šè‹¥æœ‰çŸ›ç›¾æˆ–æŸ¥ä¸åˆ°çš„éƒ¨åˆ†ï¼Œè«‹å¦‚å¯¦èªªæ˜ã€‚
    """
    
    res = llm.invoke([HumanMessage(content=prompt)])
    final_ans = res.content
    
    # å¿«å–è™•ç†
    try:
        if not os.path.exists(CACHE_FILE): cache = {}
        else:
            with open(CACHE_FILE, "r", encoding="utf-8") as f: cache = json.load(f)
        cache[state['input_query']] = final_ans
        with open(CACHE_FILE, "w", encoding="utf-8") as f: json.dump(cache, f, ensure_ascii=False, indent=4)
    except: pass
    
    return {"final_answer": final_ans}

# --- 5. æ§‹å»ºåœ–è¡¨ ---
workflow = StateGraph(State)
workflow.add_node("check_cache", check_cache_node)
workflow.add_node("planner", planner_node)
workflow.add_node("query_gen", query_gen_node)
workflow.add_node("search_tool", search_node)
workflow.add_node("vlm_process", vlm_and_value_node)
workflow.add_node("output", output_node)

workflow.set_entry_point("check_cache")
workflow.add_conditional_edges("check_cache", lambda x: "hit" if x.get("final_answer") else "miss", {"hit": "output", "miss": "planner"})
workflow.add_conditional_edges("planner", lambda x: "y" if x["is_sufficient"] else "n", {"y": "output", "n": "query_gen"})
workflow.add_edge("query_gen", "search_tool")
workflow.add_edge("search_tool", "vlm_process")
workflow.add_edge("vlm_process", "planner")
workflow.add_edge("output", END)

app = workflow.compile()

# --- 6. åŸ·è¡Œä»‹é¢ ---
if __name__ == "__main__":
    print("\nğŸ•µï¸ æ·±åº¦äº‹å¯¦æŸ¥è­‰å¼•æ“å•Ÿå‹•...")
    while True:
        print(app.get_graph().print_ascii())
        user_input = input("\nğŸ” è«‹è¼¸å…¥è¦æŸ¥è­‰çš„å•é¡Œ (exit é€€å‡º)ï¼š").strip()
        if not user_input or user_input.lower() == 'exit': break
        
        result = app.invoke({
            "input_query": user_input, 
            "knowledge_base": "", 
            "keywords": [], 
            "loop_count": 0, 
            "final_answer": "", 
            "visited_urls": []
        })
        
        print("\n" + "â˜…"*35)
        print("âœ¨ ã€ æœ€çµ‚æŸ¥è­‰å ±å‘Š ã€‘")
        print(result['final_answer'])
        print(f"ğŸ“Š èª¿æŸ¥çµ±è¨ˆï¼šæ­·ç¶“ {result['loop_count']} è¼ªèª¿æŸ¥ï¼Œå…±æƒæ {len(result['visited_urls'])} å€‹ç¶²é ")
        print("â˜…"*35)