import os
import json
import base64
import requests
from typing import TypedDict, List, Annotated
import operator
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END
from playwright.sync_api import sync_playwright

# --- 1. ç’°å¢ƒè¨­å®š ---
SEARXNG_URL = "https://puli-8080.huannago.com/search"
CACHE_FILE = "qa_cache.json"

llm = ChatOpenAI(
    base_url="https://ws-05.huannago.com/v1",
    api_key="YOUR_API_KEY", 
    model="google/gemma-3-27b-it",
    temperature=0 
)

# --- 2. ç‹€æ…‹å®šç¾© ---
class State(TypedDict):
    input_query: str
    knowledge_base: str
    keywords: List[str]
    search_links: List[dict]
    visited_urls: Annotated[List[str], operator.add]
    final_answer: str
    is_sufficient: bool 
    loop_count: int

# --- 3. æ ¸å¿ƒå·¥å…· ---
def internal_vlm_read_website(url: str, original_query: str) -> str:
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            page = browser.new_page()
            page.set_viewport_size({"width": 1280, "height": 900})
            page.goto(url, wait_until="domcontentloaded", timeout=30000)
            page.wait_for_timeout(3000)
            b64 = base64.b64encode(page.screenshot()).decode('utf-8')
            browser.close()
            
            msg = [
                {"type": "text", "text": f"""ä½ æ˜¯ä¸€ä½äº‹å¯¦åˆ†æå®˜ã€‚è«‹é‡å°ç”¨æˆ¶çš„å•é¡Œã€Œ{original_query}ã€åˆ†ææ­¤ç¶²é æˆªåœ–ï¼š
                1. **ä¾†æºæ€§è³ª**ï¼šè©²ç¶²é æ˜¯å¦ç‚ºå®˜æ–¹ç™¼å¸ƒã€æ¬Šå¨å ±å°æˆ–ä¸€èˆ¬ç¤¾ç¾¤è¨è«–ï¼Ÿ
                2. **æ ¸å¿ƒäº‹å¯¦**ï¼šæå–æ‰€æœ‰èˆ‡å•é¡Œç›¸é—œçš„æ™‚é–“ã€æ•¸æ“šæˆ–äº‹ä»¶ç‹€æ…‹ã€‚
                3. **è®ŠåŒ–è¨˜éŒ„**ï¼šè‹¥å•é¡Œæ¶‰åŠè®Šå‹•ï¼Œè«‹ç²¾ç¢ºè¨˜éŒ„ã€Œè®Šå‹•å‰ã€èˆ‡ã€Œè®Šå‹•å¾Œã€çš„å…·é«”å…§å®¹ã€‚
                4. **å¯ä¿¡åº¦**ï¼šå…§å®¹ä¸­æ˜¯å¦æœ‰æ¨™è¨»ã€å‚³èã€ã€ã€çŒœæ¸¬ã€æˆ–ã€éå®˜æ–¹è­‰å¯¦ã€ç­‰å­—çœ¼ï¼Ÿ"""},
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64}"}}
            ]
            res = llm.invoke([HumanMessage(content=msg)])
            return res.content
    except Exception as e: return f"è®€å–éŒ¯èª¤: {e}"

# --- 4. æµç¨‹ç¯€é»å¯¦ç¾ (å®Œå…¨ä¸å«æ¨™çš„è³‡è¨Š) ---

def check_cache_node(state: State):
    print(f"ğŸ” [æ­¥é©Ÿ 1] æª¢æŸ¥å¿«å–...")
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            cache = json.load(f)
            if state['input_query'] in cache:
                print("ğŸ¯ [å‘½ä¸­å¿«å–]")
                return {"final_answer": cache[state['input_query']]}
    return {"knowledge_base": "", "loop_count": 0, "visited_urls": []}

def planner_node(state: State):
    if state['loop_count'] >= 5: return {"is_sufficient": True}

    print(f"ğŸ§  [æ­¥é©Ÿ 2] æ±ºç­–è©•ä¼° (ç¬¬ {state['loop_count']} è¼ª)...")
    prompt = f"""ç”¨æˆ¶å•é¡Œï¼š{state['input_query']}
    ç•¶å‰æ”¶é›†è³‡è¨Šï¼š{state['knowledge_base']}
    
    è«‹åˆ¤æ–·ï¼š
    1. è³‡è¨Šæ˜¯å¦åŒ…å«ä¾†è‡ªå®˜æ–¹ä¸»é«”ï¼ˆç›¸é—œå…¬å¸/æ©Ÿæ§‹ï¼‰çš„ç›´æ¥è­‰æ“šï¼Ÿ
    2. å¦‚æœå•é¡Œæ¶‰åŠæ¬¡æ•¸è¨ˆç®—ï¼Œæ˜¯å¦æœ‰æ˜ç¢ºçš„è®ŠåŒ–æ­·ç¨‹è¨˜éŒ„ï¼Ÿ
    3. æ˜¯å¦æœ‰è¶³å¤ è­‰æ“šæ’é™¤ç¬¬ä¸‰æ–¹åª’é«”çš„çŒœæ¸¬ï¼Ÿ
    
    è³‡è¨Šæ˜¯å¦å……è£•ï¼Ÿè«‹å›ç­” y æˆ– nã€‚"""
    
    res = llm.invoke([HumanMessage(content=prompt)])
    return {"is_sufficient": 'y' in res.content.lower()}

def query_gen_node(state: State):
    print("\nğŸ’¡ [æ­¥é©Ÿ 3] å‹•æ…‹ç”Ÿæˆèˆ‡ä¿®æ­£æœå°‹ç­–ç•¥...")
    
    # æå–å…ˆå‰çš„æœå°‹æ­·å²èˆ‡ç›®å‰çš„çŸ¥è­˜å„²å‚™
    past_keywords = state.get('keywords', [])
    current_kb = state.get('knowledge_base', 'ç›®å‰å°šç„¡æœ‰æ•ˆè³‡è¨Š')
    
    # å»ºæ§‹å¼•å° Promptï¼Œè®“ LLM å…·å‚™ã€Œåæ€ã€èƒ½åŠ›
    history_str = f"å·²å˜—è©¦éçš„é—œéµå­—ï¼š{', '.join(past_keywords)}" if past_keywords else "é€™æ˜¯ç¬¬ä¸€æ¬¡æœå°‹ã€‚"
    
    prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æƒ…å ±åˆ†æå®˜ã€‚
    ã€ç”¨æˆ¶å•é¡Œã€‘ï¼š{state['input_query']}
    ã€æœå°‹æ­·å²ã€‘ï¼š{history_str}
    ã€ç›®å‰æŒæ¡è³‡è¨Šç°¡è¿°ã€‘ï¼š{current_kb[:500]}... (ç•¥)

    è«‹åŸ·è¡Œä»¥ä¸‹æ€è€ƒï¼š
    1. æª¢è¦–ç›®å‰è³‡è¨Šæ˜¯å¦å·²è¶³ä»¥å›ç­”å•é¡Œï¼Ÿ
    2. å¦‚æœä¸è¶³ï¼Œæ˜¯å› ç‚ºã€Œæ‰¾ä¸åˆ°å®˜ç¶²ã€ã€ã€Œè³‡è¨Šå¤ªèˆŠã€é‚„æ˜¯ã€Œç¼ºä¹å…·é«”æ•¸æ“šã€ï¼Ÿ
    3. é¿é–‹å·²å˜—è©¦éçš„é—œéµå­—ï¼Œç”Ÿæˆä¸€å€‹æ›´é«˜ç²¾ç¢ºåº¦ã€è‹±æ–‡ç‚ºä¸»çš„é—œéµå­—ã€‚
    
    è«‹ç›´æ¥å›å‚³é—œéµå­—å­—ä¸²ï¼Œä¸è¦è§£é‡‹èªªæ˜ã€‚"""
    
    res = llm.invoke([HumanMessage(content=prompt)])
    new_kw = res.content.strip().replace('"', '').replace('*', '')
    
    # --- é—œéµä¿®æ”¹ï¼šPrint å‡ºç”Ÿæˆçš„é—œéµå­—ä»¥åˆ©è§€æ¸¬ ---
    print(f"ğŸ”„ ç­–ç•¥ä¿®æ­£ä¸­...")
    print(f"   â†³ åŸå§‹å•é¡Œï¼š{state['input_query']}")
    if past_keywords:
        print(f"   â†³ æ­·å²é—œéµå­—ï¼š{past_keywords}")
    print(f"   â†³ âœ¨ æ–°ç”Ÿæˆçš„å„ªåŒ–é—œéµå­—ï¼šã€ {new_kw} ã€‘")
    
    return {"keywords": state.get('keywords', []) + [new_kw]}

def search_node(state: State):
    print(f"ğŸ“¡ [æ­¥é©Ÿ 4] æª¢ç´¢ç¶²è·¯è³‡æº...")
    try:
        r = requests.get(SEARXNG_URL, params={"q": state['keywords'][-1], "format": "json"}, timeout=15).json()
        return {"search_links": r.get('results', [])[:3]}
    except: return {"search_links": []}

def vlm_and_value_node(state: State):
    print("ğŸ“¸ [æ­¥é©Ÿ 5] VLM äº‹å¯¦æå–...")
    links = state.get('search_links', [])
    new_info = ""
    for link in links:
        if link['url'] in state['visited_urls']: continue
        print(f"ğŸ“– é–±è®€ä¾†æºï¼š{link['url'][:50]}...")
        info = internal_vlm_read_website(link['url'], state['input_query'])
        new_info += f"\n[ä¾†æº: {link['url']}]\n{info}\n"
        break 
    return {"knowledge_base": state['knowledge_base'] + new_info, "visited_urls": [link['url']], "loop_count": state['loop_count'] + 1}

def output_node(state: State):
    if state.get("final_answer"): return state
    print("ğŸ [æ­¥é©Ÿ 6] å½™æ•´æœ€çµ‚äº‹å¯¦å ±å‘Š...")
    prompt = f"""è«‹é‡å°ç”¨æˆ¶å•é¡Œã€Œ{state['input_query']}ã€ç”¢å‡ºæŸ¥è­‰å ±å‘Šã€‚
    
    ã€è¦å‰‡ã€‘ï¼š
    1. **è­‰æ“šåˆ†ç´š**ï¼šå„ªå…ˆæ¡ç”¨å®˜æ–¹ä¸»é«”çš„ç›´æ¥è­‰æ“šï¼Œæ’é™¤æœªç¶“è­‰å¯¦çš„å‚³èã€‚
    2. **è®ŠåŒ–æ ¸å°**ï¼šå¦‚æœæ¶‰åŠè®Šå‹•æ¬¡æ•¸ï¼Œè«‹åˆ—å‡ºå…·é«”çš„æ™‚é–“è»¸ç¯€é»ã€‚
    3. **èª å¯¦æ€§**ï¼šè‹¥è­‰æ“šä¸è¶³ï¼Œè«‹å¦‚å¯¦èªªæ˜å“ªäº›éƒ¨åˆ†å±¬æ–¼å®˜æ–¹ç¢ºå®šï¼Œå“ªäº›å±¬æ–¼åª’é«”æ¨æ¸¬ã€‚
    
    ç­†è¨˜å…§å®¹ï¼š
    {state['knowledge_base']}"""
    
    res = llm.invoke([HumanMessage(content=prompt)])
    final_ans = res.content
    
    # å¿«å–è™•ç†
    try:
        if not os.path.exists(CACHE_FILE): cache = {}
        else:
            with open(CACHE_FILE, "r", encoding="utf-8") as f: cache = json.load(f)
        cache[state['input_query']] = final_ans
        with open(CACHE_FILE, "w", encoding="utf-8") as f: json.dump(cache, f, ensure_ascii=False, indent=4)
    except: pass
    
    return {"final_answer": final_ans}

# --- 5. æ§‹å»ºåœ–è¡¨ ---



workflow = StateGraph(State)
workflow.add_node("check_cache", check_cache_node)
workflow.add_node("planner", planner_node)
workflow.add_node("query_gen", query_gen_node)
workflow.add_node("search_tool", search_node)
workflow.add_node("vlm_process", vlm_and_value_node)
workflow.add_node("output", output_node)

workflow.set_entry_point("check_cache")
workflow.add_conditional_edges("check_cache", lambda x: "hit" if x.get("final_answer") else "miss", {"hit": "output", "miss": "planner"})
workflow.add_conditional_edges("planner", lambda x: "y" if x["is_sufficient"] else "n", {"y": "output", "n": "query_gen"})
workflow.add_edge("query_gen", "search_tool")
workflow.add_edge("search_tool", "vlm_process")
workflow.add_edge("vlm_process", "planner")
workflow.add_edge("output", END)

app = workflow.compile()

# --- 6. åŸ·è¡Œä»‹é¢ ---
if __name__ == "__main__":
    print("\n" + "="*50)
    print("ğŸ•µï¸ é€šç”¨å‹è‡ªå¾‹äº‹å¯¦æŸ¥è­‰å¼•æ“ (æ¨™çš„å»ä¸­å¿ƒåŒ–ç‰ˆ)")
    try: app.get_graph().print_ascii()
    except: pass
    print("="*50)

    while True:
        user_input = input("\nğŸ” è«‹è¼¸å…¥è¦æŸ¥è­‰çš„å•é¡Œ (exit é€€å‡º)ï¼š").strip()
        if not user_input or user_input.lower() == 'exit': break
        
        # åŸ·è¡Œä¸¦é¡¯ç¤ºéç¨‹
        result = app.invoke({
            "input_query": user_input, 
            "knowledge_base": "", 
            "keywords": [], 
            "loop_count": 0, 
            "final_answer": "", 
            "visited_urls": []
        })
        
        print("\n" + "â˜…"*25)
        print("âœ¨ ã€ æŸ¥ è­‰ å ± å‘Š ã€‘")
        print(result['final_answer'])
        print(f"ğŸ“Š èª¿æŸ¥æ·±åº¦ï¼š{result['loop_count']} è¼ª")
        print("â˜…"*25)